{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maria-lin/How-to-make-notebook-in-dataiku/blob/main/notebook_dataiku__explique.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b2dc1af2",
      "metadata": {
        "id": "b2dc1af2"
      },
      "source": [
        "# Notebook Dataiku ‚Äî Analyse exploratoire & D√©tection d‚Äôanomalies (DAB / GAB)\n",
        "\n",
        "Ce notebook est con√ßu pour **Dataiku DSS** et pour ton cas : **transactions de retraits** agr√©g√©es par automate.  \n",
        "Il fait :\n",
        "\n",
        "1. **Chargement Dataiku**  \n",
        "2. **Audit qualit√©** (types, valeurs manquantes, incoh√©rences)  \n",
        "3. **EDA profonde** (stats + plots)  \n",
        "4. **Features non √©videntes** (ratios/coh√©rences)  \n",
        "5. **D√©tection d‚Äôanomalies non supervis√©e** (Isolation Forest)  \n",
        "6. **Sortie actionnable** : *Top anomalies* + raisons simples + export vers Dataiku (optionnel)\n",
        "\n",
        "‚úÖ **Important :** Tu n‚Äôas **pas** de colonne `anomalie`, donc on **n‚Äôutilise pas** de matrice de confusion.  \n",
        "√Ä la place, on fait une **validation non supervis√©e** : coh√©rence des distributions, stabilit√©, interpr√©tation.\n",
        "\n",
        "---\n",
        "\n",
        "## Colonnes attendues (d‚Äôapr√®s ce que tu as donn√©)\n",
        "\n",
        "- `num_automate` (int64)  \n",
        "- `lib_site_implementation` (object)  \n",
        "- `code_banque` (int64)  \n",
        "- `type_carte` (object)  \n",
        "- `montant_total` (float)  \n",
        "- `nb_total_de_retraits` (int)  \n",
        "- `type_gab_e_i` (int : 2 valeurs possibles, ex : E/I)  \n",
        "- `code_postale_emplacement` (int64)  \n",
        "- `dab_hos_site` (object : `B`=bureau / `H`=hors site)  \n",
        "- `typ_gab` (object : retraits uniquement)\n",
        "\n",
        "Si une colonne manque, certaines cellules afficheront un message et passeront.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cf97bc8",
      "metadata": {
        "id": "6cf97bc8"
      },
      "outputs": [],
      "source": [
        "# === 0) Imports & options d'affichage ===\n",
        "# Cette cellule importe les librairies n√©cessaires et configure l'affichage.\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "\n",
        "pd.set_option(\"display.max_columns\", 200)\n",
        "pd.set_option(\"display.float_format\", lambda x: f\"{x:,.2f}\")\n",
        "\n",
        "# Pour avoir des r√©sultats reproductibles\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2dd932d",
      "metadata": {
        "id": "f2dd932d"
      },
      "source": [
        "## 1) Chargement des donn√©es (Dataiku)\n",
        "\n",
        "**Ce que fait le code :**\n",
        "- R√©cup√®re un dataset Dataiku par son nom\n",
        "- Le convertit en DataFrame pandas `df`\n",
        "\n",
        "**Sortie attendue :**\n",
        "- `Shape` (nb lignes/colonnes)\n",
        "- aper√ßu des premi√®res lignes (`df.head()`)\n",
        "\n",
        "‚ö†Ô∏è **Action pour toi :** remplace `DATASET_NAME` par le nom exact de ton dataset dans Dataiku.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6e486639",
      "metadata": {
        "id": "6e486639"
      },
      "outputs": [],
      "source": [
        "import dataiku\n",
        "\n",
        "# üîß √Ä MODIFIER : nom exact du dataset Dataiku\n",
        "DATASET_NAME = \"TON_DATASET_DAB\"\n",
        "\n",
        "dataset = dataiku.Dataset(DATASET_NAME)\n",
        "df = dataset.get_dataframe()\n",
        "\n",
        "print(\"Shape (lignes, colonnes) =\", df.shape)\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "320166aa",
      "metadata": {
        "id": "320166aa"
      },
      "source": [
        "## 2) Audit qualit√© (senior-style)\n",
        "\n",
        "On v√©rifie syst√©matiquement :\n",
        "- **Types** et colonnes pr√©sentes\n",
        "- **Valeurs manquantes**\n",
        "- **Doublons**\n",
        "- **Incoh√©rences** (ex : montant_total > 0 alors que nb_total_de_retraits == 0)\n",
        "\n",
        "**Sorties attendues :**\n",
        "- `df.info()` : types + non-null counts\n",
        "- tableau des % de valeurs manquantes\n",
        "- compte des doublons\n",
        "- compte d‚Äôincoh√©rences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "45706ee8",
      "metadata": {
        "id": "45706ee8"
      },
      "outputs": [],
      "source": [
        "# 2.1 Types & compl√©tude\n",
        "df.info()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a25b9fda",
      "metadata": {
        "id": "a25b9fda"
      },
      "outputs": [],
      "source": [
        "# 2.2 Valeurs manquantes (% par colonne)\n",
        "missing_pct = (df.isna().mean().sort_values(ascending=False) * 100).round(2)\n",
        "missing_pct[missing_pct > 0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3033e74a",
      "metadata": {
        "id": "3033e74a"
      },
      "outputs": [],
      "source": [
        "# 2.3 Doublons\n",
        "dup_rows = int(df.duplicated().sum())\n",
        "dup_automate = int(df.duplicated(subset=[\"num_automate\"]).sum()) if \"num_automate\" in df.columns else None\n",
        "{\"doublons_lignes\": dup_rows, \"doublons_num_automate\": dup_automate}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6e1d1dd",
      "metadata": {
        "id": "a6e1d1dd"
      },
      "outputs": [],
      "source": [
        "# 2.4 Contr√¥les de coh√©rence (adaptables)\n",
        "checks = {}\n",
        "\n",
        "if \"montant_total\" in df.columns:\n",
        "    checks[\"montant_total_negatif\"] = int((df[\"montant_total\"] < 0).sum())\n",
        "    checks[\"montant_total_zero\"] = int((df[\"montant_total\"] == 0).sum())\n",
        "\n",
        "if \"nb_total_de_retraits\" in df.columns:\n",
        "    checks[\"nb_retraits_negatif\"] = int((df[\"nb_total_de_retraits\"] < 0).sum())\n",
        "    checks[\"nb_retraits_zero\"] = int((df[\"nb_total_de_retraits\"] == 0).sum())\n",
        "\n",
        "# incoh√©rence : montant positif mais 0 retrait\n",
        "if \"montant_total\" in df.columns and \"nb_total_de_retraits\" in df.columns:\n",
        "    checks[\"incoherence_montant_pos_nb0\"] = int(((df[\"montant_total\"] > 0) & (df[\"nb_total_de_retraits\"] == 0)).sum())\n",
        "\n",
        "checks\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e2233930",
      "metadata": {
        "id": "e2233930"
      },
      "source": [
        "## 3) Comprendre les variables cat√©gorielles\n",
        "\n",
        "**Ce que fait le code :**\n",
        "- Liste les modalit√©s (top) et leurs fr√©quences pour :\n",
        "  - `lib_site_implementation`\n",
        "  - `type_carte`\n",
        "  - `dab_hos_site`\n",
        "  - `typ_gab`\n",
        "\n",
        "**Pourquoi c‚Äôest utile :**\n",
        "- D√©tecter des valeurs inattendues (ex : typo, nouvelle modalit√©)\n",
        "- V√©rifier si une variable est constante (ex : `typ_gab` toujours \"RETRAIT\")\n",
        "\n",
        "**Sortie attendue :**\n",
        "- `n_unique` + top 15 des valeurs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87360f0c",
      "metadata": {
        "id": "87360f0c"
      },
      "outputs": [],
      "source": [
        "cat_cols = [c for c in [\"lib_site_implementation\",\"type_carte\",\"dab_hos_site\",\"typ_gab\"] if c in df.columns]\n",
        "\n",
        "for c in cat_cols:\n",
        "    print(\"\\n===\", c, \"===\")\n",
        "    print(\"n_unique:\", df[c].nunique(dropna=False))\n",
        "    display(df[c].value_counts(dropna=False).head(15))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a2dd7119",
      "metadata": {
        "id": "a2dd7119"
      },
      "source": [
        "## 4) Statistiques descriptives des variables num√©riques\n",
        "\n",
        "**Ce que fait le code :**\n",
        "- R√©sume les variables num√©riques avec percentiles (1%, 5%, 50%, 95%, 99%).\n",
        "\n",
        "**Pourquoi :**\n",
        "- Les percentiles aident √† voir les extr√™mes sans inventer des seuils arbitraires.\n",
        "\n",
        "**Sortie attendue :**\n",
        "- Tableau `describe()` transpos√©\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "559f5516",
      "metadata": {
        "id": "559f5516"
      },
      "outputs": [],
      "source": [
        "num_cols = [c for c in [\n",
        "    \"montant_total\",\n",
        "    \"nb_total_de_retraits\",\n",
        "    \"type_gab_e_i\",\n",
        "    \"code_postale_emplacement\",\n",
        "    \"code_banque\"\n",
        "] if c in df.columns]\n",
        "\n",
        "df[num_cols].describe(percentiles=[.01,.05,.25,.5,.75,.95,.99]).T\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6fd749db",
      "metadata": {
        "id": "6fd749db"
      },
      "source": [
        "## 5) Visualisations EDA (plots ‚Äúqui parlent‚Äù)\n",
        "\n",
        "On veut voir :\n",
        "- **la forme** des distributions (asym√©trie, queue √† droite)\n",
        "- la relation **montant_total vs nb_total_de_retraits**\n",
        "- une comparaison **B vs H** (bureau vs hors site) si disponible\n",
        "\n",
        "**Sorties attendues :**\n",
        "- histogramme nb_total_de_retraits\n",
        "- histogramme log(1+montant_total)\n",
        "- scatter plot (nuage de points)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ae0f36e",
      "metadata": {
        "id": "0ae0f36e"
      },
      "outputs": [],
      "source": [
        "def hist(series, title, bins=40, log1p=False):\n",
        "    s = series.dropna()\n",
        "    if log1p:\n",
        "        s = np.log1p(s)\n",
        "        title = title + \" (log1p)\"\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.hist(s, bins=bins)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(series.name)\n",
        "    plt.ylabel(\"count\")\n",
        "    plt.show()\n",
        "\n",
        "if \"nb_total_de_retraits\" in df.columns:\n",
        "    hist(df[\"nb_total_de_retraits\"], \"Distribution du nombre total de retraits\")\n",
        "\n",
        "if \"montant_total\" in df.columns:\n",
        "    hist(df[\"montant_total\"], \"Distribution du montant total\", log1p=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1eaebd83",
      "metadata": {
        "id": "1eaebd83"
      },
      "outputs": [],
      "source": [
        "# Scatter montant_total vs nb_total_de_retraits (+ segment B/H si pr√©sent)\n",
        "if \"nb_total_de_retraits\" in df.columns and \"montant_total\" in df.columns:\n",
        "    plt.figure(figsize=(7,6))\n",
        "    if \"dab_hos_site\" in df.columns:\n",
        "        for v in df[\"dab_hos_site\"].dropna().unique():\n",
        "            d = df[df[\"dab_hos_site\"] == v]\n",
        "            plt.scatter(d[\"nb_total_de_retraits\"], d[\"montant_total\"], alpha=0.5, label=str(v))\n",
        "        plt.legend(title=\"dab_hos_site\")\n",
        "    else:\n",
        "        plt.scatter(df[\"nb_total_de_retraits\"], df[\"montant_total\"], alpha=0.5)\n",
        "\n",
        "    plt.xlabel(\"nb_total_de_retraits\")\n",
        "    plt.ylabel(\"montant_total\")\n",
        "    plt.title(\"Montant total vs Nombre total de retraits\")\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Colonnes manquantes pour le scatter (nb_total_de_retraits/montant_total).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c7579524",
      "metadata": {
        "id": "c7579524"
      },
      "source": [
        "## 6) Features non √©videntes (les plus utiles pour l‚Äôanomalie)\n",
        "\n",
        "Au lieu de regarder ‚Äúbeaucoup de retraits‚Äù ou ‚Äúmontant √©lev√©‚Äù, on cr√©e des indicateurs plus intelligents :\n",
        "\n",
        "### 6.1 Montant moyen par retrait\n",
        "`montant_moyen_par_retrait = montant_total / nb_total_de_retraits`\n",
        "\n",
        "- Tr√®s bas ‚Üí retraits fractionn√©s (√©vitement de seuils, comportement atypique)\n",
        "- Tr√®s haut ‚Üí retraits unitaires atypiques\n",
        "\n",
        "### 6.2 Ratio montant vs attendu\n",
        "On calcule une **r√©f√©rence globale** (m√©diane du montant moyen), puis :\n",
        "`montant_attendu = nb_total_de_retraits * median(montant_moyen_par_retrait)`\n",
        "`ratio_montant_vs_attendu = montant_total / montant_attendu`\n",
        "\n",
        "- << 1 : montant ‚Äútrop faible‚Äù vs volume\n",
        "- >> 1 : montant ‚Äútrop √©lev√©‚Äù vs volume\n",
        "\n",
        "**Sorties attendues :**\n",
        "- nouvelles colonnes ajout√©es\n",
        "- stats descriptives + boxplots\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "94f6949c",
      "metadata": {
        "id": "94f6949c"
      },
      "outputs": [],
      "source": [
        "df_feat = df.copy()\n",
        "\n",
        "if \"montant_total\" in df_feat.columns and \"nb_total_de_retraits\" in df_feat.columns:\n",
        "    df_feat[\"montant_moyen_par_retrait\"] = df_feat[\"montant_total\"] / df_feat[\"nb_total_de_retraits\"].replace(0, np.nan)\n",
        "\n",
        "    ref = float(np.nanmedian(df_feat[\"montant_moyen_par_retrait\"]))\n",
        "    df_feat[\"montant_attendu\"] = df_feat[\"nb_total_de_retraits\"] * ref\n",
        "    df_feat[\"ratio_montant_vs_attendu\"] = df_feat[\"montant_total\"] / df_feat[\"montant_attendu\"].replace(0, np.nan)\n",
        "\n",
        "    display(df_feat[[\"montant_moyen_par_retrait\",\"ratio_montant_vs_attendu\"]].describe(percentiles=[.01,.05,.5,.95,.99]).T)\n",
        "else:\n",
        "    print(\"Impossible de cr√©er les features (montant_total ou nb_total_de_retraits manquant).\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7437a72c",
      "metadata": {
        "id": "7437a72c"
      },
      "outputs": [],
      "source": [
        "# Boxplots simples (matplotlib) pour visualiser les valeurs extr√™mes\n",
        "def boxplot(series, title):\n",
        "    s = series.dropna()\n",
        "    plt.figure(figsize=(8,3))\n",
        "    plt.boxplot(s, vert=False, showfliers=True)\n",
        "    plt.title(title)\n",
        "    plt.xlabel(series.name)\n",
        "    plt.show()\n",
        "\n",
        "if \"montant_moyen_par_retrait\" in df_feat.columns:\n",
        "    boxplot(df_feat[\"montant_moyen_par_retrait\"], \"Boxplot ‚Äî Montant moyen par retrait\")\n",
        "\n",
        "if \"ratio_montant_vs_attendu\" in df_feat.columns:\n",
        "    boxplot(df_feat[\"ratio_montant_vs_attendu\"], \"Boxplot ‚Äî Ratio montant vs attendu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf1c60ac",
      "metadata": {
        "id": "cf1c60ac"
      },
      "source": [
        "## 7) D√©tection d‚Äôanomalies (Isolation Forest)\n",
        "\n",
        "**Pourquoi Isolation Forest :**\n",
        "- M√©thode **non supervis√©e** (pas besoin de labels)\n",
        "- D√©tecte des observations rares dans un espace multi-variables (montant, volume, ratios, contexte)\n",
        "\n",
        "**Ce que fait le code :**\n",
        "1. S√©lectionne les colonnes utiles (num√©riques + features + cat√©gories)\n",
        "2. Encode les cat√©gories (LabelEncoder)\n",
        "3. Remplit les NA (m√©diane pour num√©riques)\n",
        "4. Standardise (StandardScaler)\n",
        "5. Entra√Æne Isolation Forest\n",
        "6. Ajoute :\n",
        "   - `prediction_anomalie` (1=anomalie, 0=normal)\n",
        "   - `anomaly_score` (plus grand = plus anormal)\n",
        "\n",
        "**Sortie attendue :**\n",
        "- r√©partition (combien d‚Äôanomalies)\n",
        "- top 30 anomalies tri√©es par score\n",
        "- scatter plot des anomalies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "43f3a9ca",
      "metadata": {
        "id": "43f3a9ca"
      },
      "outputs": [],
      "source": [
        "model_df = df_feat.copy()\n",
        "\n",
        "cat_cols = [c for c in [\"lib_site_implementation\",\"type_carte\",\"dab_hos_site\",\"typ_gab\"] if c in model_df.columns]\n",
        "num_cols = [c for c in [\n",
        "    \"montant_total\",\"nb_total_de_retraits\",\"type_gab_e_i\",\"code_postale_emplacement\",\"code_banque\",\n",
        "    \"montant_moyen_par_retrait\",\"ratio_montant_vs_attendu\"\n",
        "] if c in model_df.columns]\n",
        "\n",
        "use_cols = cat_cols + num_cols\n",
        "X_raw = model_df[use_cols].copy()\n",
        "\n",
        "# Encodage des cat√©gories\n",
        "encoders = {}\n",
        "for c in cat_cols:\n",
        "    le = LabelEncoder()\n",
        "    X_raw[c] = X_raw[c].astype(str).fillna(\"NA\")\n",
        "    X_raw[c] = le.fit_transform(X_raw[c])\n",
        "    encoders[c] = le\n",
        "\n",
        "# Remplissage NA pour les num√©riques\n",
        "for c in num_cols:\n",
        "    X_raw[c] = pd.to_numeric(X_raw[c], errors=\"coerce\")\n",
        "    X_raw[c] = X_raw[c].fillna(X_raw[c].median())\n",
        "\n",
        "# Standardisation\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X_raw)\n",
        "\n",
        "# Mod√®le (contamination = proportion attendue d'anomalies ; ajuste selon ton contexte)\n",
        "iso = IsolationForest(\n",
        "    n_estimators=400,\n",
        "    contamination=0.08,\n",
        "    random_state=RANDOM_STATE\n",
        ")\n",
        "\n",
        "pred = iso.fit_predict(X)  # 1 normal, -1 anomalie\n",
        "model_df[\"prediction_anomalie\"] = np.where(pred == -1, 1, 0)\n",
        "\n",
        "# Score d'anomalie (plus grand = plus anormal)\n",
        "model_df[\"anomaly_score\"] = -iso.score_samples(X)\n",
        "\n",
        "model_df[\"prediction_anomalie\"].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03423bdf",
      "metadata": {
        "id": "03423bdf"
      },
      "outputs": [],
      "source": [
        "# Visualisation : anomalies dans l'espace montant_total / nb_total_de_retraits\n",
        "if \"nb_total_de_retraits\" in model_df.columns and \"montant_total\" in model_df.columns:\n",
        "    plt.figure(figsize=(7,6))\n",
        "    normal = model_df[model_df[\"prediction_anomalie\"] == 0]\n",
        "    anom = model_df[model_df[\"prediction_anomalie\"] == 1]\n",
        "\n",
        "    plt.scatter(normal[\"nb_total_de_retraits\"], normal[\"montant_total\"], alpha=0.35, label=\"normal\")\n",
        "    plt.scatter(anom[\"nb_total_de_retraits\"], anom[\"montant_total\"], alpha=0.85, label=\"anomalie\")\n",
        "\n",
        "    plt.xlabel(\"nb_total_de_retraits\")\n",
        "    plt.ylabel(\"montant_total\")\n",
        "    plt.title(\"Anomalies d√©tect√©es (Isolation Forest)\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Colonnes manquantes pour le scatter anomalies.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b610073d",
      "metadata": {
        "id": "b610073d"
      },
      "source": [
        "## 8) Donner des raisons simples (interpr√©tabilit√©)\n",
        "\n",
        "Un mod√®le d‚Äôanomalie doit √™tre **actionnable**.  \n",
        "On g√©n√®re donc une colonne `raison` bas√©e sur des percentiles (faible/√©lev√©) des features cl√©s.\n",
        "\n",
        "**Ce que fait le code :**\n",
        "- Calcule des seuils (5% / 95%) sur `montant_moyen_par_retrait` et `ratio_montant_vs_attendu`\n",
        "- Attribue une raison lisible par ligne\n",
        "\n",
        "**Sortie attendue :**\n",
        "- un tableau des anomalies avec `raison`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc774163",
      "metadata": {
        "id": "fc774163"
      },
      "outputs": [],
      "source": [
        "# Seuils (percentiles) pour g√©n√©rer des explications simples\n",
        "q = {}\n",
        "\n",
        "for col in [\"montant_moyen_par_retrait\", \"ratio_montant_vs_attendu\"]:\n",
        "    if col in model_df.columns:\n",
        "        q[(col, \"p05\")] = model_df[col].quantile(0.05)\n",
        "        q[(col, \"p95\")] = model_df[col].quantile(0.95)\n",
        "\n",
        "def reason(row):\n",
        "    reasons = []\n",
        "    if \"montant_moyen_par_retrait\" in row and pd.notna(row[\"montant_moyen_par_retrait\"]):\n",
        "        if (\"montant_moyen_par_retrait\",\"p05\") in q and row[\"montant_moyen_par_retrait\"] < q[(\"montant_moyen_par_retrait\",\"p05\")]:\n",
        "            reasons.append(\"montant moyen tr√®s faible (fractionnement possible)\")\n",
        "        if (\"montant_moyen_par_retrait\",\"p95\") in q and row[\"montant_moyen_par_retrait\"] > q[(\"montant_moyen_par_retrait\",\"p95\")]:\n",
        "            reasons.append(\"montant moyen tr√®s √©lev√© (retraits unitaires atypiques)\")\n",
        "\n",
        "    if \"ratio_montant_vs_attendu\" in row and pd.notna(row[\"ratio_montant_vs_attendu\"]):\n",
        "        if (\"ratio_montant_vs_attendu\",\"p05\") in q and row[\"ratio_montant_vs_attendu\"] < q[(\"ratio_montant_vs_attendu\",\"p05\")]:\n",
        "            reasons.append(\"montant total faible vs attendu (incoh√©rence volume/montant)\")\n",
        "        if (\"ratio_montant_vs_attendu\",\"p95\") in q and row[\"ratio_montant_vs_attendu\"] > q[(\"ratio_montant_vs_attendu\",\"p95\")]:\n",
        "            reasons.append(\"montant total √©lev√© vs attendu (incoh√©rence volume/montant)\")\n",
        "\n",
        "    if \"dab_hos_site\" in row and str(row[\"dab_hos_site\"]) == \"H\":\n",
        "        reasons.append(\"hors site (profil d'exposition diff√©rent)\")\n",
        "\n",
        "    return \" | \".join(reasons) if reasons else \"profil rare multi-variables\"\n",
        "\n",
        "# Appliquer seulement sur les anomalies pour √™tre plus lisible\n",
        "anoms = model_df[model_df[\"prediction_anomalie\"] == 1].copy()\n",
        "anoms[\"raison\"] = anoms.apply(reason, axis=1)\n",
        "\n",
        "cols_show = [c for c in [\n",
        "    \"num_automate\",\"lib_site_implementation\",\"code_banque\",\"type_carte\",\n",
        "    \"montant_total\",\"nb_total_de_retraits\",\"montant_moyen_par_retrait\",\"ratio_montant_vs_attendu\",\n",
        "    \"dab_hos_site\",\"type_gab_e_i\",\"code_postale_emplacement\",\n",
        "    \"anomaly_score\",\"raison\"\n",
        "] if c in anoms.columns]\n",
        "\n",
        "anoms.sort_values(\"anomaly_score\", ascending=False)[cols_show].head(30)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "39c863ce",
      "metadata": {
        "id": "39c863ce"
      },
      "source": [
        "## 9) Validation non supervis√©e (sans matrice de confusion)\n",
        "\n",
        "Sans label, on v√©rifie la **coh√©rence** du r√©sultat en comparant :\n",
        "- la distribution des variables pour les anomalies vs le reste\n",
        "\n",
        "**Sortie attendue :**\n",
        "- tableau comparatif (m√©dianes, p95)\n",
        "- conclusion qualitative : les anomalies sont ‚Äúdiff√©rentes‚Äù sur des indicateurs cl√©s\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d2be3917",
      "metadata": {
        "id": "d2be3917"
      },
      "outputs": [],
      "source": [
        "anoms = model_df[model_df[\"prediction_anomalie\"] == 1]\n",
        "normal = model_df[model_df[\"prediction_anomalie\"] == 0]\n",
        "\n",
        "cols_check = [c for c in [\n",
        "    \"montant_total\",\"nb_total_de_retraits\",\"montant_moyen_par_retrait\",\"ratio_montant_vs_attendu\"\n",
        "] if c in model_df.columns]\n",
        "\n",
        "summary = pd.DataFrame({\n",
        "    \"median_normal\": normal[cols_check].median(),\n",
        "    \"median_anom\": anoms[cols_check].median(),\n",
        "    \"p95_normal\": normal[cols_check].quantile(0.95),\n",
        "    \"p95_anom\": anoms[cols_check].quantile(0.95),\n",
        "})\n",
        "summary\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a885df62",
      "metadata": {
        "id": "a885df62"
      },
      "source": [
        "## 10) Stabilit√© (option pro)\n",
        "\n",
        "On refait Isolation Forest avec plusieurs valeurs de `contamination` (ex : 5%, 8%, 12%) et on regarde si les **top anomalies** restent les m√™mes.\n",
        "\n",
        "**Pourquoi :**\n",
        "- Les anomalies ‚Äús√©rieuses‚Äù sont souvent d√©tect√©es m√™me si on change l√©g√®rement le param√®tre.\n",
        "\n",
        "**Sortie attendue :**\n",
        "- taille de l‚Äôintersection des top-30 entre param√®tres\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9dfa8baa",
      "metadata": {
        "id": "9dfa8baa"
      },
      "outputs": [],
      "source": [
        "def top_ids_for_contamination(cont, top_k=30):\n",
        "    iso_tmp = IsolationForest(n_estimators=400, contamination=cont, random_state=RANDOM_STATE)\n",
        "    pred_tmp = iso_tmp.fit_predict(X)\n",
        "    score_tmp = -iso_tmp.score_samples(X)\n",
        "    tmp = model_df.copy()\n",
        "    tmp[\"score_tmp\"] = score_tmp\n",
        "    if \"num_automate\" in tmp.columns:\n",
        "        return set(tmp.sort_values(\"score_tmp\", ascending=False)[\"num_automate\"].head(top_k))\n",
        "    else:\n",
        "        # fallback si num_automate absent\n",
        "        return set(tmp.sort_values(\"score_tmp\", ascending=False).head(top_k).index)\n",
        "\n",
        "tops_05 = top_ids_for_contamination(0.05)\n",
        "tops_08 = top_ids_for_contamination(0.08)\n",
        "tops_12 = top_ids_for_contamination(0.12)\n",
        "\n",
        "{\n",
        "    \"top_commun_05_08\": len(tops_05 & tops_08),\n",
        "    \"top_commun_08_12\": len(tops_08 & tops_12),\n",
        "    \"top_commun_05_12\": len(tops_05 & tops_12),\n",
        "}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "32cab2e3",
      "metadata": {
        "id": "32cab2e3"
      },
      "source": [
        "## 11) Export vers un dataset Dataiku (optionnel)\n",
        "\n",
        "**Ce que fait le code :**\n",
        "- √âcrit le top anomalies vers un dataset Dataiku de sortie.\n",
        "\n",
        "‚úÖ **Action pour toi :**\n",
        "- Cr√©e un dataset vide de sortie dans Dataiku (schema auto) nomm√© `DAB_ANOMALIES_OUT` (ou ton nom).\n",
        "- Modifie `OUT_DATASET_NAME`.\n",
        "\n",
        "**Sortie attendue :**\n",
        "- un dataset Dataiku rempli avec le top anomalies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5a5f7cd5",
      "metadata": {
        "id": "5a5f7cd5"
      },
      "outputs": [],
      "source": [
        "# üîß Optionnel : √©crire vers Dataiku\n",
        "OUT_DATASET_NAME = \"DAB_ANOMALIES_OUT\"\n",
        "\n",
        "top_out = anoms.sort_values(\"anomaly_score\", ascending=False)[cols_show].head(200).copy()\n",
        "\n",
        "try:\n",
        "    out_ds = dataiku.Dataset(OUT_DATASET_NAME)\n",
        "    out_ds.write_with_schema(top_out)\n",
        "    print(\"‚úÖ √âcrit dans Dataiku :\", OUT_DATASET_NAME, \"| lignes =\", len(top_out))\n",
        "except Exception as e:\n",
        "    print(\"‚ö†Ô∏è Export Dataiku non effectu√©. Raison :\", e)\n",
        "    print(\"üëâ Si tu veux exporter : cr√©e le dataset de sortie dans Dataiku et v√©rifie son nom.\")\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}